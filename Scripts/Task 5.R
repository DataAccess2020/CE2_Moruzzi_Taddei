### TASK 5 ###

# meaning of "crawl"

## to crawl in the field of computer science means to collect data from the Internet

# meaning of "web spider"

# web spiders, or web crawlers, are programs that collect large amounts 
# of data from the internet at the same time through hyperlinks methodically and 
# automatically by browsing and downloading web pages. when a web crawler is used 
# to simultaneously download web pages and extract data from them it is called a web scraper

# differences between web spider and scraping done in task 4

# In task 4 to scrape the beppegrillo.it blog we used web scraping tools inside of
# R, to do that we had to use specific R packages. the main difference is that we did 
# all the work inside the R environment. Another difference is that we had to 
# collect the URLs we needed manually, and then parse and extract data from those URLs. 
# Instead, incorporating the crawling process into R through the package Rcrawler 
# we could have automatically parsed and crawled all the URLs in a specific domain.


# functions to build a spider scraper + which arguments


install.packages("Rcrawler")













































